{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91e6e2-6213-47b7-a544-b634bbcd3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read both csv files. You can use “pandas” or “polars” libraries to read it as dataframe in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3e2726-fc8e-49db-9dc8-067078a5f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8930f73-697d-4e8d-9b2d-19f5498c0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a74198-c950-4e09-b9a6-b62f87a4eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a60345-7955-4153-9eba-7166e90e6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pl.read_csv(\"train.csv\")\n",
    "test_file = pl.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68225fd2-d7a8-44f3-8e9a-07007d6e106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each review, remove all <br /> tokens. You can use “re” library in Python that uses regular expressions\n",
    "#or you can use any other library of your choice that allow string removl/replacement.\n",
    "#and\n",
    "# Change labels from text to integers (0 for negative and 1 for positive).\n",
    "# You can do it directly in pandas dataframe or use scikit-learn label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956c7449-655a-4535-a68e-e62fdb93f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(<br />)' #() was the solution bro..... [] :(\n",
    "# Replace all occurrences of character s with an empty string\n",
    "#For the train csv file\n",
    "updated_dict = {}\n",
    "review_list=[]\n",
    "sentiment_list = []\n",
    "for row in range(0,2000):    \n",
    "    string = train_file.row(row,named = True) #reads the data in each row, and convert it in dictionary.\n",
    "    mod_string = re.sub(pattern,'',string['review']) #relace the word <br /> with ''>\n",
    "    string['review'] = mod_string #the review will be updated with removed word.\n",
    "    review_list.append(mod_string) #that review will be appended in a list of reviews\n",
    "    sentiment_list.append(string['sentiment'])    #whatever the sentiment is for that review, it will aslo be appended \n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(sentiment_list)\n",
    "labeled_list1 = list(le.transform(sentiment_list))\n",
    "\n",
    "updated_dict['review'] = review_list\n",
    "updated_dict['sentiment'] = labeled_list1 # 0  and 1 representation of the labels.\n",
    "\n",
    "modified_data = pl.DataFrame(updated_dict)\n",
    "modified_data.write_csv(\"modified_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2c73a4-0539-432b-8612-5ebf7ee00c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(<br />)' #() was the solution bro..... [] :(\n",
    "# Replace all occurrences of character s with an empty string\n",
    "#For the train csv file\n",
    "updated_dict2 = {} #for test\n",
    "review_list2=[] #for test\n",
    "sentiment_list2 = [] # for test\n",
    "for row in range(0,500):    \n",
    "    string2 = test_file.row(row,named = True) #reads the data in each row, and convert it in dictionary.\n",
    "    mod_string2 = re.sub(pattern,'',string2['review']) #relace the word <br /> with ''>\n",
    "    string2['review'] = mod_string2 #the review will be updated with removed word.\n",
    "    review_list2.append(mod_string2) #that review will be appended in a list of reviews\n",
    "    sentiment_list2.append(string2['sentiment']) #whatever the sentiment is for that review, it will aslo be appended \n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(sentiment_list2)\n",
    "labeled_list = list(le.transform(sentiment_list2))\n",
    "updated_dict2['review'] = review_list2\n",
    "updated_dict2['sentiment'] = labeled_list #Converted the labels to 0(negative) and 1(positive) \n",
    "\n",
    "modified_data2 = pl.DataFrame(updated_dict2) #converts dictionary in to a dataframe\n",
    "modified_data2.write_csv(\"modified_test.csv\") #writes it into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a192521-b96e-443a-abef-0b8009d86b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out labels and texts. You should have train texts, train labels, test texts, \n",
    "# and test labels in separate variables.\n",
    "# split into train test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_file2 = pl.read_csv(\"modified_train.csv\")\n",
    "# train_texts, train_labels = train_test_split(train_file2)\n",
    "train_texts = review_list\n",
    "train_labels = labeled_list1\n",
    "test_texts = review_list2\n",
    "test_labels = labeled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99a3d181-e068-4aa6-b161-697d718f089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For the preprocessed texts above, convert them to vectors based on frequency \n",
    "#(counts) using scikit-learn. Do this for both train and test splits. Remember, you \n",
    "#can only use train texts to determine the vocabulary of the dataset. Hint: You \n",
    "#will have one vectorizer that has seen training data and will be used to transform \n",
    "#the testing data.\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b182b1b5-8523-486e-97c1-c2a4935c8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# To create a Count Vectorizer, we simply need to instantiate one.\n",
    "# There are special parameters we can set here when making the vectorizer, but\n",
    "# for the most basic example, it is not needed.\n",
    "vectorizer = CountVectorizer(binary = True)\n",
    "\n",
    "# To actually create the vectorizer, we simply need to call fit on the text\n",
    "# data that we wish to fix\n",
    "train_vector = vectorizer.fit_transform(train_texts).toarray()\n",
    "test_vector = vectorizer.transform(test_texts).toarray()\n",
    "\n",
    "\n",
    "# print(train_vector.shape, test_vector.shape)\n",
    "# vd_train = pl.DataFrame(data=train_array,schema = vectorizer.get_feature_names())\n",
    "# vd_train.write_csv(\"counterized_train.csv\") #writes it into a csv file.\n",
    "# print(vd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650b6d45-36f5-484d-831d-0d8d5e98824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.feature_selection.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "info_gain = mutual_info_classif(train_vector,train_labels,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f609ac10-9d00-4c85-bef5-798c17a52f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25235"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a46da8e-b0c4-4d5e-97ec-06552e11f7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPdemo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# fd = pl.DataFrame(data=info_gain,schema = vectorizer.get_feature_names())\n",
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a81a00-6715-4c5c-8370-3b60c0706306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25235"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6866ced1-660e-490f-ac27-8c0905fbcc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for val in range(25235):\n",
    "    data_dict[features[val]] = info_gain[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b86f6a8-4935-4e7c-9d05-37fbc8975635",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict_data = sorted(data_dict.items(), key = lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b30dc2e3-7b3f-4a5e-aee5-77993d7105a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00', 0.0)\n",
      "('000', 0.0)\n",
      "('04', 0.0)\n",
      "('07', 0.0)\n",
      "('10', 0.0)\n",
      "('101', 0.0)\n",
      "('102', 0.0)\n",
      "('103', 0.0)\n",
      "('10the', 0.0)\n",
      "('10this', 0.0)\n"
     ]
    }
   ],
   "source": [
    "for it in range(10):\n",
    "    print(sorted_dict_data[it])\n",
    "#Bottom Ten features with info gain value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a53ec194-4f1f-4c92-bb13-7c4afb23c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('obtrusive', 0.04852586544958659), ('bad', 0.04233031764907125), ('paleontologist', 0.042286314254307955), ('toothpaste', 0.0421768284270978), ('uribe', 0.041171971141280794), ('lucas', 0.04083139728660079), ('awful', 0.040299617256842835), ('cultivation', 0.03969472814433961), ('burr', 0.039481084137305666), ('excellent', 0.038772235612442696), ('somehow', 0.038439951385150994)]\n"
     ]
    }
   ],
   "source": [
    "top_ten_features= []\n",
    "for it2 in range(-11,0,1):\n",
    "    top_ten_features.append(sorted_dict_data[it2])\n",
    "print(top_ten_features[::-1])\n",
    "#Top 10 features with info gain greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82f2e825-f733-4025-8937-006f97b0e282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25235)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_array) #TRAIN AND TEST SHAPES NOT SAME.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb493814-5e8d-484e-b160-6d0d7b29eaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 12366)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_array) #TRAIN AND TEST SHAPES DON;T MATHC :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "790edbfa-e5d7-4b7c-9c6d-a814377e59fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "220b7b24-6ec1-4efb-9b04-73a9a5f8ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_selection import SelectPercentile as SP\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "selector = SP(score_func=mutual_info_classif,percentile=49.005) # #49.005 Matches the X of decision tree. Features.\n",
    "selector.fit(train_vector,train_labels)\n",
    "X_reduced = selector.transform(train_vector)\n",
    "X_test_reduced = selector.transform(test_vector)\n",
    "model_4 = DTC(criterion=\"entropy\").fit(X_reduced,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d309f71c-4010-4273-ac4f-4f738f7a8d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 12366), (500,), (500, 25235))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced.shape, np.array(test_labels).shape, test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0509187b-9e9f-41f5-86d2-cc65cb5071e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.702\n"
     ]
    }
   ],
   "source": [
    "score_4 = model_4.score(X_test_reduced,np.array(test_labels)) #Model_4/score_4 is for reduced features.\n",
    "print(f\"Score = {score_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f919abbf-1ffe-4add-a15d-5de933bd6edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_1:0.672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_selection import SelectPercentile as SP\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "model_1 = DTC(criterion=\"entropy\").fit(train_vector,train_labels)\n",
    "score_1 = model_1.score(test_vector,test_labels)\n",
    "print(f\"score_1:{score_1}\") #Model_1 and score_1 is fpr whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b385c29b-d046-4a6c-9370-d6497dc1e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_w_fselect = model_4.predict(X_test_reduced)#y_prediction with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf8c5b8f-ea63-4ee3-925a-b48ab7acd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_without_fs = model_1.predict(test_vector)#y_prediction without doing feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85a599cc-5e41-4d51-8bf7-e1a93a568282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149  90]\n",
      " [ 81 180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64       239\n",
      "           1       0.67      0.69      0.68       261\n",
      "\n",
      "    accuracy                           0.66       500\n",
      "   macro avg       0.66      0.66      0.66       500\n",
      "weighted avg       0.66      0.66      0.66       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Output Precision, Recall, and F1 score of all three decision trees on respective test splits\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(test_labels, y_pred_without_fs))\n",
    "print(classification_report(test_labels, y_pred_without_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "285c1d6e-f4a1-4cc8-9464-2c8684cc8a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[162  77]\n",
      " [ 72 189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68       239\n",
      "           1       0.71      0.72      0.72       261\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.70      0.70      0.70       500\n",
      "weighted avg       0.70      0.70      0.70       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Output Precision, Recall, and F1 score of all three decision trees on respective test splits\n",
    "print(confusion_matrix(test_labels, y_pred_w_fselect))\n",
    "print(classification_report(test_labels, y_pred_w_fselect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f64f0eba-53bc-4334-b136-37b03ddae426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 12366)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "425ce603-7770-475c-a456-b271b1d37b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25235)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d3182-337b-40b5-9fc7-3c0785ff6e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
